# Import the requests library to make web requests
import requests
# Import the BeautifulSoup library to parse the HTML content
from bs4 import BeautifulSoup

from selenium import webdriver

from selenium.webdriver.chrome.service import Service

from selenium.webdriver.support.ui import WebDriverWait

from webdriver_manager.chrome import ChromeDriverManager

import time

import locale


# Define the URL of the web page that contains the list of NASDAQ 100 companies
url = "https://www.cnbc.com/nasdaq-100/"


# Create an empty list to store the company symbols
symbols = []

def scrape_symb(url):

    chrome_options = webdriver.ChromeOptions()
    chrome_options.add_argument('--ignore-certifiate-errors')
    chrome_options.add_argument('--ignore-ssl-errors')

    chrome_path= r"C:\Desktop\chromedriver.exe"
    service = Service(executable_path=chrome_path)
    driver = webdriver.Chrome(service=service, options=chrome_options)

    wait =WebDriverWait(driver,2)

    driver.get(url)
    time.sleep(5)
    
    # Create a BeautifulSoup object from the response text
    soup = BeautifulSoup(driver.page_source, features = "lxml")
    rows = soup.select(selector=".BasicTable-symbolName")
    symbols_final=[]
    for row in rows:
        symbols_final.append(row.getText())

    #check if dublicates in list
    return symbols_final


def scrape_p(url):
    chrome_options = webdriver.ChromeOptions()
    chrome_options.add_argument('--ignore-certifiate-errors')
    chrome_options.add_argument('--ignore-ssl-errors')

    chrome_path= r"C:\Desktop\chromedriver.exe"
    service = Service(executable_path=chrome_path)
    driver = webdriver.Chrome(service=service, options=chrome_options)

    wait =WebDriverWait(driver,2)

    driver.get(url)
    time.sleep(5)
    
    # Create a BeautifulSoup object from the response text
    soup = BeautifulSoup(driver.page_source, features = "lxml")
    rows = soup.select(selector=".BasicTable-unchanged.BasicTable-numData")
    
    price_final=[]

    #could try this instead of all the locale stuff
    #float("123,456.908".replace(',',''))

    locale.setlocale(locale.LC_ALL, '')

    for row in rows:
        price_final.append(locale.atof(row.getText()))

    #check if dublicates in list
    
    return price_final



print(scrape_p(url))

